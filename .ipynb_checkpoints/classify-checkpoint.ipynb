{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "from sklearn.svm import SVC\n",
    "from help import helper as hp\n",
    "from help.utils import Timer\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ekspresi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expressions = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "expressions = np.array(expressions)\n",
    "expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset dan model\n",
    "kfold = hp.loadjson('dataset/kfold.json')\n",
    "# models = np.unique([model.split('.')[3] for model in os.listdir('model/dae')])#.................percobaan Semua model\n",
    "# models = hp.aemodels(cfrom=550, cto=450, cstep=10, n_layer=1)#..................................percobaan 'All'\n",
    "# models = hp.aemodels(hfrom=1000, hto=1000, hstep=1, cfrom=500, cto=400, cstep=10, n_layer=2)#...percobaan 'Asia Tenggara'\n",
    "# models = hp.aemodels(cfrom=450, cto=350, cstep=10, n_layer=1)#..................................percobaan 'Asia Timur'\n",
    "# models = hp.aemodels(hfrom=1000, hto=1000, hstep=1, cfrom=550, cto=450, cstep=10, n_layer=2)#...percobaan 'Eropa Utara'\n",
    "models = hp.aemodels(cfrom=450, cto=350, cstep=10, n_layer=1)#..................................percobaan 'Amerika Serikat'\n",
    "\n",
    "dpaths = np.array([f'dataset/vectors/dae/{path}' for path in os.listdir('dataset/vectors/dae')])\n",
    "scores = {}\n",
    "scorestime = {}\n",
    "models\n",
    "# looping per dataset\n",
    "# dkeys = list(kfold.keys())\n",
    "# dkeys = ['all']\n",
    "# dkeys = ['race Asia Tenggara']\n",
    "# dkeys = ['race Asia Timur']\n",
    "# dkeys = ['race Eropa Utara']\n",
    "dkeys = ['race Amerika Serikat']\n",
    "for dkey in dkeys:\n",
    "    # jika ingin learning dengan semua data atau per ras ubah kondisi menjadi (if 'all' in dkey or 'race' in dkey:)\n",
    "    # jika ingin learning semua dataset ubah kondisi menjadi (if True or 'all' in dkey or 'race' in dkey:)\n",
    "    if 'all' in dkey or 'race' in dkey:\n",
    "        scores[dkey] = {'train':{}, 'test':{}}\n",
    "        scorestime[dkey] = {}\n",
    "        # looping fold\n",
    "        for fkey in kfold[dkey]:\n",
    "            scores[dkey]['train'][fkey] = {}\n",
    "            scores[dkey]['test'][fkey] = {}\n",
    "            scorestime[dkey][fkey] = {}\n",
    "            # looping model\n",
    "            for model in models:\n",
    "                clayer = model.split('-')[-1]\n",
    "                clayer = int(clayer)\n",
    "                # jika ingin learning dengan layer step 50, ubah kondisi ke (if clayer % 50 == 0:)\n",
    "                # jika ingin learning semua layer ubah kondisi ke (if True or clayer % 50 == 0:)\n",
    "                if True or clayer % 50 == 0:\n",
    "                    # load data training\n",
    "                    x = []\n",
    "                    for wholedkey in kfold[dkey][fkey]['train']:\n",
    "                        train_index = kfold[dkey][fkey]['train'][wholedkey]\n",
    "                        x.extend(load(f'dataset/vectors/dae/{wholedkey}.{model}.jlb')[train_index])\n",
    "                    x = np.array(x)\n",
    "                    y = expressions[x[:,-1].astype(np.int)]\n",
    "                    x = x[:,:-1]\n",
    "\n",
    "                    # learning\n",
    "                    hp.sprint(f'learning ({dkey}|{fkey}|{model})...')\n",
    "                    timer = Timer().start()\n",
    "#                     svm = load(f'model/svm/kfold/svm.{dkey}.{fkey}.{model}.jlb')\n",
    "                    svm = SVC(kernel='linear')\n",
    "                    svm.fit(x, y)\n",
    "                    timer.end()\n",
    "                    dump(svm, f'model/svm/kfold/svm.{dkey}.{fkey}.{model}.jlb')\n",
    "                    hp.sprint(f'\\rlearned ({dkey}|{fkey}|{model}) => {timer.summary(f=2)}')\n",
    "                    scorestime[dkey][fkey][model] = timer.summary(f=2)\n",
    "\n",
    "                    #score data training\n",
    "                    scoretr = np.around(svm.score(x, y) * 100, 2)\n",
    "                    scores[dkey]['train'][fkey][model] = scoretr\n",
    "                    hp.sprint(f'\\rlearned ({dkey}|{fkey}|{model}|acctr:{scoretr}%) => {timer.summary(f=2)}')\n",
    "\n",
    "                    # load data testing\n",
    "                    x = []\n",
    "                    for wholedkey in kfold[dkey][fkey]['test']:\n",
    "                        test_index = kfold[dkey][fkey]['test'][wholedkey]\n",
    "                        x.extend(load(f'dataset/vectors/dae/{wholedkey}.{model}.jlb')[test_index])\n",
    "                    x = np.array(x)\n",
    "                    y = expressions[x[:,-1].astype(np.int)]\n",
    "                    x = x[:,:-1]\n",
    "\n",
    "                    #score data testing\n",
    "                    scorett = np.around(svm.score(x, y) * 100, 2)\n",
    "                    scores[dkey]['test'][fkey][model] = scorett\n",
    "                    hp.sprint(f'\\rlearned ({dkey}|{fkey}|{model}|acctr:{scoretr}%|acctt:{scorett}%) => {timer.summary(f=2)}\\n')\n",
    "    if len(dkeys) == 1:\n",
    "        break\n",
    "        \n",
    "for dkey in scores:\n",
    "    for typekey in scores[dkey]:\n",
    "        scores[dkey][typekey]['mean'] = {}\n",
    "        for model in models:\n",
    "            clayer = model.split('-')[-1]\n",
    "            clayer = int(clayer)\n",
    "            if True or clayer % 50 == 0:\n",
    "                # mean per model\n",
    "                mpm = []\n",
    "                for fkey in range(5):\n",
    "                    fkey = f'Fold {fkey}'\n",
    "                    score = scores[dkey][typekey][fkey][model]\n",
    "                    mpm.append(score)\n",
    "                mpm = np.around(np.array(mpm).mean(), 2)\n",
    "                scores[dkey][typekey]['mean'][model] = mpm\n",
    "\n",
    "if len(dkeys) == 1:\n",
    "    hp.savejson(f'score/scores_{dkey}.json', scores)\n",
    "    hp.savejson(f'score/scorestime_{dkey}.json', scorestime)\n",
    "    hp.savejson(f'score/scoreswithmean_{dkey}.json', scores)\n",
    "else:\n",
    "    hp.savejson(f'score/scores.json', scores)\n",
    "    hp.savejson(f'score/scorestime.json', scorestime)\n",
    "    hp.savejson(f'score/scoreswithmean.json', scores)\n",
    "print('done...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning semua data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asia tenggara | 0.5 detik\n",
      "asia timur | 14.95 detik\n",
      "eropa utara | 0.27 detik\n",
      "amerika serikat | 0.55 detik\n",
      "all | 44.83 detik\n"
     ]
    }
   ],
   "source": [
    "race = {\n",
    "    'asia tenggara': ['1000-410', 'hijrah'],\n",
    "    'asia timur': ['430', 'jaffe', 'caspeal', 'nvie'],\n",
    "    'eropa utara': ['1000-550', 'kdef'],\n",
    "    'amerika serikat': ['400', 'ck+', 'facesdb'],\n",
    "    'all': ['550', 'all'],\n",
    "}\n",
    "\n",
    "for ras in race:\n",
    "    model = race[ras][0]\n",
    "    dataset = race[ras][1:]\n",
    "    \n",
    "    # load dataset\n",
    "    x = []\n",
    "    for name in dataset:\n",
    "        x.extend(load(f'dataset/vectors/dae/{name}.{model}.jlb'))\n",
    "    x = np.array(x)\n",
    "    y = expressions[x[:,-1].astype(np.int)]\n",
    "    x = x[:,:-1]\n",
    "    \n",
    "    # learning\n",
    "    timer = Timer().start()\n",
    "    svm = SVC(kernel='linear')\n",
    "    svm.fit(x, y)\n",
    "    timer.end()\n",
    "    dump(svm, f'model/svm/all/{ras}.jlb')\n",
    "    print(f'{ras} | {timer.summary(f=2)}')\n",
    "    \n",
    "    del x\n",
    "    del y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
